
### 各工具协调,区别与关联
1. Redis,传统数据库,hbase,hive 每个之间的区别(问的非常细)?

	* Redis是缓存，围绕着内存和缓存说
	* Hbase是列式数据库，存在hdfs上，围绕着数据量来说
	* Hive是数据仓库，是用来分析数据的，不是增删改查数据的。

2. kafka+spark-streaming结合丢数据怎么解决？
spark streaming从1.2开始提供了数据的零丢失，想享受这个特性，需要满足如下条件：
	* 1. 数据输入需要可靠的sources和可靠的receivers
	* 2. 应用metadata必须通过应用driver checkpoint
	* 3. WAL（write ahead log）
	
	> 1.1. 可靠的sources和receivers
	
	> spark streaming可以通过多种方式作为数据sources（包括kafka），输入数据通过receivers接收，通过replication存储于spark中（为faultolerance，默认复制到两个spark executors），如果数据复制完成，receivers可以知道（例如kafka中更新offsets到zookeeper中）。这样当receivers在接收数据过程中crash掉，不会有数据丢失，receivers没有复制的数据，当receiver恢复后重新接收。

 

	> 1.2. metadata checkpoint
	
	> 可靠的sources和receivers，可以使数据在receivers失败后恢复，然而在driver失败后恢复是比较复杂的，一种方法是通过checkpoint metadata到HDFS或者S3。metadata包括：

	> · configuration
	
	> · code
	
	> · 一些排队等待处理但没有完成的RDD（仅仅是metadata，而不是data）

	> 这样当driver失败时，可以通过metadata checkpoint，重构应用程序并知道执行到那个地方。

	> 1.3. 数据可能丢失的场景

	> 可靠的sources和receivers，以及metadata checkpoint也不可以保证数据的不丢失，例如：

	> · 两个executor得到计算数据，并保存在他们的内存中

	> · receivers知道数据已经输入

	> · executors开始计算数据

	> · driver突然失败

	> · driver失败，那么executors都会被kill掉

	> · 因为executor被kill掉，那么他们内存中得数据都会丢失，但是这些数据不再被处理

	> · executor中的数据不可恢复


	> 1.4. WAL

	> 为了避免上面情景的出现，spark streaming 1.2引入了WAL。所有接收的数据通过receivers写入HDFS或者S3中checkpoint目录，这样当driver失败后，executor中数据丢失后，可以通过checkpoint恢复。



	> 1.5. At-Least-Once

	> 尽管WAL可以保证数据零丢失，但是不能保证exactly-once，例如下面场景：

	> · Receivers接收完数据并保存到HDFS或S3

	> · 在更新offset前，receivers失败了

	> · Spark Streaming以为数据接收成功，但是Kafka以为数据没有接收成功，因为offset没有更新到zookeeper

	> · 随后receiver恢复了

	> · 从WAL可以读取的数据重新消费一次，因为使用的kafka High-Level消费API，从zookeeper中保存的offsets开始消费

	> 1.6. WAL的缺点

	> 通过上面描述，WAL有两个缺点：

	> · 降低了receivers的性能，因为数据还要存储到HDFS等分布式文件系统

	> · 对于一些resources，可能存在重复的数据，比如Kafka，在Kafka中存在一份数据，在Spark Streaming也存在一份（以WAL的形式存储在hadoop API兼容的文件系统中）

	> 1.7. Kafka direct API

	> 为了WAL的性能损失和exactly-once，spark streaming1.3中使用Kafka direct API。非常巧妙，Spark driver计算下个batch的offsets，指导executor消费对应的topics和partitions。消费Kafka消息，就像消费文件系统文件一样。

	> 1. 不再需要kafka receivers，executor直接通过Kafka API消费数据

	> 2. WAL不再需要，如果从失败恢复，可以重新消费

	> 3. exactly-once得到了保证，不会再从WAL中重复读取数据

	> 1.8. 总结
	
	> 主要说的是spark streaming通过各种方式来保证数据不丢失，并保证exactly-once，每个版本都是spark streaming越来越稳定，越来越向生产环境使用发展。

2. storm和spark-streaming：为什么用storm不同spark-streaming?
	* 处理模型,延迟
		* 虽然这两个框架都提供可扩展性和容错性,它们根本的区别在于他们的处理模型。而Storm处理的是每次传入的一个事件，而Spark Streaming是处理某个时间段窗口内的事件流。因此,Storm处理一个事件可以达到秒内的延迟，而Spark Streaming则有几秒钟的延迟。
	* 容错、数据保证
		* 在容错数据保证方面的权衡是，Spark Streaming提供了更好的支持容错状态计算。在Storm中,每个单独的记录当它通过系统时必须被跟踪，所以Storm能够至少保证每个记录将被处理一次，但是在从错误中恢复过来时候允许出现重复记录。这意味着可变状态可能不正确地被更新两次。
	* 另一方面，Spark Streaming只需要在批级别进行跟踪处理，因此可以有效地保证每个mini-batch将完全被处理一次，即便一个节点发生故障。(实际上,Storm的 Trident library库也提供了完全一次处理。但是,它依赖于事务更新状态,这比较慢,通常必须由用户实现。)
3. mr和spark区别，怎么理解spark-rdd?
	* Mr是文件方式的分布式计算框架，是将中间结果和最终结果记录在文件中，map和reduce的数据分发也是在文件中。
	* spark是内存迭代式的计算框架，计算的中间结果可以缓存内存，也可以缓存硬盘，但是不是每一步计算都需要缓存的。
Spark-rdd是一个数据的分区记录集合………………


----
