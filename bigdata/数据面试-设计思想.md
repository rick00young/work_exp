## 数据面试-设计思想
### 数据设计思想相关

1. 设计日志收集分析系统 
日志分布在各个业务系统中，我们需要对当天的日志进行实时汇总统计，同时又能按天查询历史的汇总数据（可以围绕PV、UV、IP等 
指标进行阐述） 
	* 1、通过flume将不同系统的日志收集到kafka中 
	* 2、通过storm实时的处理PV、UV、IP 
	* 3、通过kafka的consumer将日志生产到hbase中。 
	* 4、通过离线的mapreduce或者hive，处理hbase中的数据 

2. Redis,传统数据库,hbase,hive 每个之间的区别 
	* redis：分布式缓存，强调缓存，内存中数据 
	* 传统数据库：注重关系 
	* hbase：列式数据库，无法做关系数据库的主外键，用于存储海量数据，底层基于hdfs 
	* hive：数据仓库工具，分析数据,底层是mapreduce。不是数据库，不能用来做用户的交互存储 

3. 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，找出a、b文件共同的url？ 
可以估计每个文件的大小为50亿×64=298G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。 
	* 1、将文件存储到hdfs中，这样每个文件为64M或者是128M 
	* 2、分别对两个文件的url进行去重、排序输出，这样能排除a文件中相同的url，b文件也一样 
	* 3、对a、b两个文件处理后的结果进行wordcount，并且在reduce中判断单词个数，个数为2的时候输出，这样就找到了a、b文件中的相同url。 
	* 4、此计算步骤中的每一步加载到内存中的文件大小都不会超过64M，远远小于4G。 

4. 一亿个数据获取前100个最大值（步骤及算法复杂度） 
两种思路： 
	* 1.根据快速排序划分的思想 
		* a. 假设数组为 array[N] (N = 1 亿)，首先利用quicksort的原理把array分成两个部分，左边部分比 array[N - 1] (array中的最后一个值， 
即pivot) 大， 右边部分比pivot 小。然后，可以得到 array[array.length - 1] (即 pivot) 在整个数组中的位置，假设是 k. 
		* b. 如果 k 比 99 大，我们在数组[0, k - 1]里找前 100 最大值。 （继续递归） 
		* c. 如果 k 比 99 小， 我们在数组[k + 1, …, N ]里找前 100 - (k + 1) 最大值。（继续递归） 
		* d. 如果 k == 99, 那么数组的前 100 个值一定是最大的。（退出） 
	* 2.先取出前100个数，维护一个100个数的最小堆，遍历一遍剩余的元素，在此过程中维护堆就可以了。具体步骤如下： 
		* step1：取前m个元素（例如m=100），建立一个小顶堆。保持一个小顶堆得性质的步骤，运行时间为O（lgm);建立一个小顶堆运行时间为m*O（lgm）=O(m lgm); 
		* step2:顺序读取后续元素，直到结束。每次读取一个元素，如果该元素比堆顶元素小，直接丢弃 如果大于堆顶元素，则用该元素替换堆顶元素，然后保持最小堆性质。最坏情况是每次都需要替换掉堆顶的最小元素，因此需要维护堆的代价为(N-m)*O(lgm); 
最后这个堆中的元素就是前最大的10W个。时间复杂度为O(N lgm）。 

	* 两种思路比较： 
	* 基于最小堆方法运行时间很稳定（每次运行时间相差很小），基于quicksort原理的方法运行时间不稳定（每次运行时间相差大）。 
Random rand = new Random(); PriorityQueue P = new PriorityQueue(); for(int i = 0,num = rand.nextInt(); (i < 100 && P.add(num)) || (i < 100000000 && (P.peek() < num && P.add(num) && P.remove() != null || 1==1)); 
i++,num = rand.nextInt()); //System.out.println(P); 

5. top K问题 
在大规模数据处理中，经常会遇到的一类问题：在海量数据中找出出现频率最好的前k个数，或者从海量数据中找出最大的前k个数，这类问题通常被称为top K问题。

> 例如，在搜索引擎中， 
统计搜索最热门的10个查询词；在歌曲库中统计下载最高的前10首歌等。 
针对top K类问题，通常比较好的方案是分治+Trie树/hash+小顶堆（就是上面提到的最小堆），即先将数据集按照Hash方法分解成多个小数据集， 
然后使用Trie树或者Hash统计每个小数据集中的query词频，之后用小顶堆求出每个数据集中出现频率最高的前K个数，最后在所有top K中求出最终的top K。 

6. 有1亿个浮点数，如果找出期中最大的10000个？ 
	* 最容易想到的方法是将数据全部排序，然后在排序后的集合中进行查找，最快的排序算法的时间复杂度一般为O（nlogn），如快速排序。但是在32位的机器上，每个float类型占4个字节，1亿个浮点数就要占用400MB的存储空间，对于一些可用内存小于400M的计算机而言，很显然是不能一次将全部数据读入内存进行排序的。 
其实即使内存能够满足要求（我机器内存都是8GB），该方法也并不高效，因为题目的目的是寻找出最大的10000个数即可，而排序却是将所有的元素都排序了，做了很多的无用功。 
	* 第二种方法为局部淘汰法，该方法与排序方法类似，用一个容器保存前10000个数，然后将剩余的所有数字——与容器内的最小数字相比，如果所有后续的元素都比容器内的10000个数还小， 
那么容器内这个10000个数就是最大10000个数。如果某一后续元素比容器内最小数字大，则删掉容器内最小元素，并将该元素插入容器，最后遍历完这1亿个数， 
得到的结果容器中保存的数即为最终结果了。此时的时间复杂度为O（n+m^2），其中m为容器的大小，即10000。 
	* 第三种方法是分治法，将1亿个数据分成100份，每份100万个数据，找到每份数据中最大的10000个，最后在剩下的100\*10000个数据里面找出最大的10000个。如果100万数据选择足够理想， 
那么可以过滤掉1亿数据里面99%的数据。100万个数据里面查找最大的10000个数据的方法如下：用快速排序的方法，将数据分为2堆，如果大的那堆个数N大于10000个， 
继续对大堆快速排序一次分成2堆，如果大的那堆个数N大于10000个，继续对大堆快速排序一次分成2堆，如果大堆个数N小于10000个，就在小的那堆里面快速排序一次，找第10000-n大的数字； 
递归以上过程，就可以找到第1w大的数。参考上面的找出第1w大数字，就可以类似的方法找到前10000大数字了。此种方法需要每次的内存空间为10^6*4=4MB，一共需要101次这样的比较。 
	* 第四种方法是Hash法。如果这1亿个书里面有很多重复的数，先通过Hash法，把这1亿个数字去重复，这样如果重复率很高的话，会减少很大的内存用量，从而缩小运算空间， 然后通过分治法或最小堆法查找最大的10000个数。 
	* 第五种方法采用最小堆。首先读入前10000个数来创建大小为10000的最小堆，建堆的时间复杂度为O（mlogm）（m为数组的大小即为10000），然后遍历后续的数字，并于堆顶（最小） 
数字进行比较。如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至1亿个数全部遍历完为止。然后按照中序遍历的方式输出当前 
堆中的所有10000个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是10000（常数）。 
实际运行： 
实际上，最优的解决方案应该是最符合实际设计需求的方案，在时间应用中，可能有足够大的内存，那么直接将数据扔到内存中一次性处理即可，也可能机器有多个核，这样可以采用 
多线程处理整个数据集。 

7. 以下是一些经常被提及的该类问题。 
	* （1）有10000000个记录，这些查询串的重复度比较高，如果除去重复后，不超过3000000个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门。请统计最热门的10个查询串， 
要求使用的内存不能超过1GB。 
	* （2）有10个文件，每个文件1GB，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。按照query的频度排序。 
	* （3）有一个1GB大小的文件，里面的每一行是一个词，词的大小不超过16个字节，内存限制大小是1MB。返回频数最高的100个词。 
	* （4）提取某日访问网站次数最多的那个IP。 
	* （5）10亿个整数找出重复次数最多的100个整数。 
	* （6）搜索的输入信息是一个字符串，统计300万条输入信息中最热门的前10条，每次输入的一个字符串为不超过255B，内存使用只有1GB。 
	* （7）有1000万个身份证号以及他们对应的数据，身份证号可能重复，找出出现次数最多的身份证号。 

8. 重复问题 
在海量数据中查找出重复出现的元素或者去除重复出现的元素也是常考的问题。针对此类问题，一般可以通过位图法实现。例如，已知某个文件内包含一些电话号码，每个号码为8位数字， 
统计不同号码的个数。 
	* 本题最好的解决方法是通过使用位图法来实现。8位整数可以表示的最大十进制数值为99999999。如果每个数字对应于位图中一个bit位，那么存储8位整数大约需要99MB。因为1B=8bit， 
所以99Mbit折合成内存为99/8=12.375MB的内存，即可以只用12.375MB的内存表示所有的8位数电话号码的内容。

9. 实时数据统计会用到哪些技术，它们各自的应用场景及区别是什么？ 
	* flume：日志收集系统，主要用于系统日志的收集 
	* kafka：消息队列，进行消息的缓存和系统的解耦 
	* storm：实时计算框架，进行流式的计算。 