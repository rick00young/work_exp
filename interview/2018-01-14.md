### 1. 什么是框架 ? 项目中引入框架的目的 ? 引入框架后解决了什么问题？


框架 顾名思义:

> 就是搭起架子,划定框子.

引入框架的目的:

> 为了相同功能代码不再重写,不只是快,还有重写出错的问题.

引入框架解决的问题:

> 1.代码规范,由于部分功能引入框架解决,所以为了统一,其他代码也要遵守规范,这样统一后,后续维护和开发都方便一些.不至于有时候维护程序员看了源码就强烈要求重写一遍.

> 2.快,少一部分代码,不用重写和调试,自然快.

> 3.协同合作,有了第一条的基础,加上框架的基础,就能多人合作开发,而不是开发中磨合.
	
### 2.框架的使用的基本的原则有哪些?一句话概括框架和类库的区别
本文源自《.NET通信框架的设计、实现与应用》书稿第一章内容

#### 什么是类库:
> 类库是一些类的集合，只要我们将一些可以复用的类集中放到一个Library中，我们就可以称其为一个类库。

> 类库中的许多元素（如类、结构、接口、枚举、委托等）之间可能有一些关联，但这些关联通常用于支持一个类概念或接口概念的完整表达。

> 如果我们从一个更高的视角来审视类库，可以发现类库中的一个个“完整的概念”之间是无关的或是关系松散的。

#### 什么是框架:

> 再来说框架，框架的第一含义是一个骨架，它封装了某领域内处理流程的控制逻辑，所以我们经常说框架是一个半成品的应用。

> 由于领域的种类是如此众多，所以框架必须具有针对性，比如，专门用于解决底层通信的框架，或专门用于医疗领域的框架。

> 框架中也包含了很多元素，但是这些元素之间关系的紧密程度要远远大于类库中元素之间的关系。框架中的所有元素都为了实现一个共同的目标而相互协作。

#### 框架与类库的区别主要表现在以下几个方面：

>（1）从结构上说，框架内部是高内聚的，而类库内部则是相对松散的。

>（2）框架封装了处理流程的控制逻辑，而类库几乎不涉及任何处理流程和控制逻辑。框架中的处理流程和控制逻辑需要经过精心的设计，因为所有使用了该框架的应用程序都会复用该设计。

>（3）框架具有IOC（控制反转）能力，而类库没有。IOC，即俗称的好莱坞模式（Don’t call us, we will call you）。对于类库中的元素来说，通常都是由我们的应用来调用它；

> 而框架具有这种能力――在适当的时候调用我们应用中的逻辑。这种能力是通过框架扩展点（或称为“插槽”）来做到的――具体的应用通过扩展点注入自己的逻辑，而在适当的时候，框架会调用这个扩展点中已注册的逻辑。

>（4）框架专注于特定领域，而类库却是更通用的。

框架着力于一个特定领域的解决方案的完整表达，而类库几乎不针对任何特定领域。比如，本书中提到的通信框架只适用于需要在TCP/UDP基础上直接构建通信的应用程序，而像正则表达式这样的类库却可以使用在各种不同的应用中。

>（5）框架通常建立在众多类库的基础之上，而类库一般不会依赖于某框架。

### 3.分布式如何实现session共享
> 1.服务器实现的session复制或session共享，这类型的共享session是和服务器紧密相关的，比如webSphere或JBOSS在搭建集群时候可以配置实现session复制或session共享，但是这种方式有一个致命的缺点，就是不好扩展和移植，比如我们更换服务器，那么就要修改服务器配置。

> 2.利用成熟的技术做session复制，比如12306使用的gemfire，比如常见的内存数据库如redis或memorycache，这类方案虽然比较普适，但是严重依赖于第三方，这样当第三方服务器出现问题的时候，那么将是应用的灾难。

> 3.将session维护在客户端，很容易想到就是利用cookie，但是客户端存在风险，数据不安全，而且可以存放的数据量比较小，所以将session维护在客户端还要对session中的信息加密。


### 4.Token认证机制
#### 几种常用的认证机制
#### HTTP Basic Auth
HTTP Basic Auth简单点说明就是每次请求API时都提供用户的username和password，简言之，Basic Auth是配合RESTful API 使用的最简单的认证方式，只需提供用户名密码即可，但由于有把用户名密码暴露给第三方客户端的风险，在生产环境下被使用的越来越少。因此，在开发对外开放的RESTful API时，尽量避免采用HTTP Basic Auth

#### OAuth
OAuth（开放授权）是一个开放的授权标准，允许用户让第三方应用访问该用户在某一web服务上存储的私密的资源（如照片，视频，联系人列表），而无需将用户名和密码提供给第三方应用。

OAuth允许用户提供一个令牌，而不是用户名和密码来访问他们存放在特定服务提供者的数据。每一个令牌授权一个特定的第三方系统（例如，视频编辑网站)在特定的时段（例如，接下来的2小时内）内访问特定的资源（例如仅仅是某一相册中的视频）。这样，OAuth让用户可以授权第三方网站访问他们存储在另外服务提供者的某些特定信息，而非所有内容

这种基于OAuth的认证机制适用于个人消费者类的互联网产品，如社交类APP等应用，但是不太适合拥有自有认证权限管理的企业应用；

#### Cookie Auth
Cookie认证机制就是为一次请求认证在服务端创建一个Session对象，同时在客户端的浏览器端创建了一个Cookie对象；通过客户端带上来Cookie对象来与服务器端的session对象匹配来实现状态管理的。默认的，当我们关闭浏览器的时候，cookie会被删除。但可以通过修改cookie 的expire time使cookie在一定时间内有效；

#### Token Auth
Token Auth的优点
Token机制相对于Cookie机制又有什么好处呢？

> * 支持跨域访问: Cookie是不允许垮域访问的，这一点对Token机制是不存在的，前提是传输的用户认证信息通过HTTP头传输.
> 
> * 无状态(也称：服务端可扩展行):Token机制在服务端不需要存储session信息，因为Token 自身包含了所有登录用户的信息，只需要在客户端的cookie或本地介质存储状态信息.

> * 更适用CDN: 可以通过内容分发网络请求你服务端的所有资料（如：javascript，HTML,图片等），而你的服务端只要提供API即可.

> * 去耦: 不需要绑定到一个特定的身份验证方案。Token可以在任何地方生成，只要在你的API被调用的时候，你可以进行Token生成调用即可.

> * 更适用于移动应用: 当你的客户端是一个原生平台（iOS, Android，Windows 8等）时，Cookie是不被支持的（你需要通过Cookie容器进行处理），这时采用Token认证机制就会简单得多。

> * CSRF:因为不再依赖于Cookie，所以你就不需要考虑对CSRF（跨站请求伪造）的防范。

> * 性能: 一次网络往返时间（通过数据库查询session信息）总比做一次HMACSHA256计算 的Token验证和解析要费时得多.

> * 不需要为登录页面做特殊处理: 如果你使用Protractor 做功能测试的时候，不再需要为登录页面做特殊处理.

> * 基于标准化:你的API可以采用标准化的 JSON Web Token (JWT). 这个标准已经存在多个后端库（.NET, Ruby, Java,Python, PHP）和多家公司的支持（如：Firebase,Google, Microsoft）.

#### 基于JWT的Token认证机制实现
JSON Web Token（JWT）是一个非常轻巧的规范。这个规范允许我们使用JWT在用户和服务器之间传递安全可靠的信息。其

JWT的组成

一个JWT实际上就是一个字符串，它由三部分组成，头部、载荷与签名。
载荷（Payload）

```
{ "iss": "Online JWT Builder", 
  "iat": 1416797419, 
  "exp": 1448333419, 
  "aud": "www.example.com", 
  "sub": "jrocket@example.com", 
  "GivenName": "Johnny", 
  "Surname": "Rocket", 
  "Email": "jrocket@example.com", 
  "Role": [ "Manager", "Project Administrator" ] 
}
```
	iss: 该JWT的签发者，是否使用是可选的；
	sub: 该JWT所面向的用户，是否使用是可选的；
	aud: 接收该JWT的一方，是否使用是可选的；
	exp(expires): 什么时候过期，这里是一个Unix时间戳，是否使用是可选的；
	iat(issued at): 在什么时候签发的(UNIX时间)，是否使用是可选的；
	其他还有：
	nbf (Not Before)：如果当前时间在nbf里的时间之前，则Token不被接受；一般都会留一些余地，比如几分钟；，是否使用是可选的；
	将上面的JSON对象进行[base64编码]可以得到下面的字符串。这个字符串我们将它称作JWT的Payload（载荷）。

```
eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9
```
小知识：Base64是一种基于64个可打印字符来表示二进制数据的表示方法。由于2的6次方等于64，所以每6个比特为一个单元，对应某个可打印字符。三个字节有24个比特，对应于4个Base64单元，即3个字节需要用4个可打印字符来表示。JDK 中提供了非常方便的 BASE64Encoder 和 BASE64Decoder，用它们可以非常方便的完成基于 BASE64 的编码和解码

头部（Header）

JWT还需要一个头部，头部用于描述关于该JWT的最基本的信息，例如其类型以及签名所用的算法等。这也可以被表示成一个JSON对象。

```
{
"typ": "JWT",
"alg": "HS256"
}
```
在头部指明了签名算法是HS256算法。
当然头部也要进行BASE64编码，编码后的字符串如下：

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9
```
签名（Signature）

将上面的两个编码后的字符串都用句号.连接在一起（头部在前），就形成了:

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0
```
最后，我们将上面拼接完的字符串用HS256算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。如果我们用mystar作为密钥的话，那么就可以得到我们加密后的内容:

```
rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM
```
最后将这一部分签名也拼接在被签名的字符串后面，我们就得到了完整的JWT:

```
eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM
```
在我们的请求URL中会带上这串JWT字符串：

```
https://your.awesome-app.com/make-friend/?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJmcm9tX3VzZXIiOiJCIiwidGFyZ2V0X3VzZXIiOiJBIn0.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM
```
认证过程
下面我们从一个实例来看如何运用JWT机制实现认证：

登录
> * 第一次认证：第一次登录，用户从浏览器输入用户名/密码，提交后到服务器的登录处理的Action层（Login Action）；
> * Login Action调用认证服务进行用户名密码认证，如果认证通过，Login Action层调用用户信息服务获取用户信息（包括完整的用户信息及对应权限信息）；
> * 返回用户信息后，Login Action从配置文件中获取Token签名生成的秘钥信息，进行Token的生成；
> * 生成Token的过程中可以调用第三方的JWT Lib生成签名后的JWT数据；
完成JWT数据签名后，将其设置到COOKIE对象中，并重定向到首页，完成登录过程；

### 5.MySQL分库的数据无缝迁移
最好的解决办法就是不迁移。不迁移肯定最好，这要依赖于非常好的设计，在前期架构设计的时候能够考虑到需求可能的变更，数据库设计也可以根据业务来进行一定程度的抽象。这可能有点太理想，不过迁移数据，始终是个不可避免的问题。下面说下一般的迁移方案。

#### 定点停机迁移
> 就像那位朋友说的，在一个月黑风高的夜晚，停掉应用，用事先写好的迁移程序，把MySQL 数据库数据迁移到新结构的MySQL数据库中。完成后，切换应用。最大的缺点就是随着数据量的增加停机时间会变得非常长。

#### MySQL binlog方案
> MySQL 的迁移可以考虑MySQL的主从复制replication的特性，解析binlog日志出来，然后根据新的业务特点设计的数据库结构，把数据写入到新的数据库，运行迁移过程不需要停机。在数据迁移基本上完成的时候，停掉前段应用，等待迁移全部完成，切换应用到新库。停机时间非常短，只需要几乎1-2分钟或者更少。

#### 触发器方案
> 备份老的MySQL数据表结构到新的MySQL数据库，在新库创建新的表结构，更改老的数据库表，创建触发器，让数据写入的时候同时写入到的新的MySQL表。dump老的MySQL的数据，导入到新的MySQL，这是新的MySQL表结构的表应该已经有相应的数据了。然后开启主从复制，让其达到跟主库数据一致。切换应用，迁移到的方案。停机时间非常短，只需要几乎1-2分钟或者更少。

#### MySQL udf方案
> MySQL的udf允许你开发自己的函数集成到MySQL中，这样你可以很方便的在数据写入的时候同时写到的其他地方。缺点是开发成本大，需要对MySQL udf有了解。也可以用现成的memcached_functions_MySQL和lib_MySQLudf_json来实现，你就不需要编写udf函数了，只需要实现一个memcached的服务端来接受数据，然后解析json到新的数据库就OK了。memcached协议非常简单，自己实现起来也很容易。这种方案的迁移时间也会非常短。

#### 中间件方案
> 这种方案必须要你的应用连接数据使用了类似中间层的方案，你只需要在中间层增加同时往新库写数据就OK了。这种方案的依赖比较大，相信小一点的公司可能都没有条件。

### 数据库事务离级别
ACID

* ⑴ 原子性（Atomicity）

> 原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

* ⑵ 一致性（Consistency）

> 一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。

> 拿转账来说，假设用户A和用户B两者的钱加起来一共是5000，那么不管A和B之间如何转账，转几次账，事务结束后两个用户的钱相加起来应该还得是5000，这就是事务的一致性。

* ⑶ 隔离性（Isolation）

> 隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

> 即要达到这么一种效果：对于任意两个并发的事务T1和T2，在事务T1看来，T2要么在T1开始之前就已经结束，要么在T1结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。
关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。

* ⑷ 持久性（Durability）

> 持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

> 例如我们在使用JDBC操作数据库时，在提交事务方法后，提示用户事务操作完成，当我们程序执行完成直到看到提示后，就可以认定事务以及正确提交，即使这时候数据库出现了问题，也必须要将我们的事务完全执行完成，否则就会造成我们看到提示事务处理完毕，但是数据库因为故障而没有执行事务的重大错误。

以上介绍完事务的四大特性(简称ACID)，现在重点来说明下事务的隔离性，当多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几种问题：

* 1.脏读

> 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。

> 当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。例如：用户A向用户B转账100元，对应SQL命令如下

    update account set money=money+100 where name=’B’;  (此时A通知B)

    update account set money=money - 100 where name=’A’;
> 当只执行第一条SQL时，A通知B查看账户，B发现确实钱已到账（此时即发生了脏读），而之后无论第二条SQL是否执行，只要该事务不提交，则所有操作都将回滚，那么当B以后再次查看账户时就会发现钱其实并没有转。

* 2.不可重复读

> 不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由于在查询间隔，被另一个事务修改并提交了。

> 例如事务T1在读取某一数据，而事务T2立马修改了这个数据并且提交事务给数据库，事务T1再次读取该数据就得到了不同的结果，发送了不可重复读。

> 不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了前一事务提交的数据。

> 在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。但在另一些情况下就有可能发生问题，例如对于同一个数据A和B依次查询就可能不同，A和B就可能打起来了……

* 3.虚读(幻读)

> 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。

> 幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。

现在来看看MySQL数据库为我们提供的四种隔离级别：

* ① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。

* ② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。

* ③ Read committed (读已提交)：可避免脏读的发生。

* ④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。

> 以上四种隔离级别最高的是Serializable级别，最低的是Read uncommitted级别，当然级别越高，执行效率就越低。像Serializable这样的级别，就是以锁表的方式(类似于Java多线程中的锁)使得其他的线程只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在MySQL数据库中默认的隔离级别为Repeatable read (可重复读)。

> 在MySQL数据库中，支持上面四种隔离级别，默认的为Repeatable read (可重复读)；而在Oracle数据库中，只支持Serializable (串行化)级别和Read committed (读已提交)这两种级别，其中默认的为Read committed级别。


### 6.贝叶斯及tf-idf为什么要和拉普拉斯平滑(Laplance Smoothing)处理?
#### 零概率问题
> 就是在计算实例的概率时，如果某个量x，在观察样本库（训练集）中没有出现过，会导致整个实例的概率结果是0。在文本分类的问题中，当一个词语没有在训练样本中出现，该词语调概率为0，使用连乘计算文本出现概率时也为0。这是不合理的，不能因为一个事件没有观察到就武断的认为该事件的概率是0。

#### 拉普拉斯的理论支撑
　　为了解决零概率的问题，法国数学家拉普拉斯最早提出用加1的方法估计没有出现过的现象的概率，所以加法平滑也叫做拉普拉斯平滑。
　　假定训练样本很大时，每个分量x的计数加1造成的估计概率变化可以忽略不计，但可以方便有效的避免零概率问题。

#### 应用举例
> 假设在文本分类中，有3个类，C1、C2、C3，在指定的训练样本中，某个词语K1，在各个类中观测计数分别为0，990，10，K1的概率为0，0.99，0.01，对这三个量使用拉普拉斯平滑的计算方法如下：
1/1003 = 0.001，991/1003=0.988，11/1003=0.011

> 在实际的使用中也经常使用加 lambda（1≥lambda≥0）来代替简单加1。如果对N个计数都加上lambda，这时分母也要记得加上N*lambda。

### linux批量重命名,删除乱码文件
```
ls * | awk '{print "mv " $0 " " $0 ".bak"}' | sh

先用 ls -li 找到文件 inode,然后 find . -inum 1233 -exec rm -rf {} \;
测试: > -h
```