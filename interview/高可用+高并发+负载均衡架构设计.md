# 高可用+高并发+负载均衡架构设计
[http://blog.csdn.net/u010370157/article/details/77870468](http://blog.csdn.net/u010370157/article/details/77870468##)
## 一、高可用
[https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959728&idx=1&sn=933227840ec8cdc35d3a33ae3fe97ec5&chksm=bd2d046c8a5a8d7a13551124af36bedf68f7a6e31f6f32828678d2adb108b86b7e08c678f22f&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959728&idx=1&sn=933227840ec8cdc35d3a33ae3fe97ec5&chksm=bd2d046c8a5a8d7a13551124af36bedf68f7a6e31f6f32828678d2adb108b86b7e08c678f22f&scene=21#wechat_redirect)
* 什么是高可用
* 高可用架构核心准则：冗余+故障转移
* 互联网分层架构，各层保证高可用的架构实践

1.什么是高可用

* 高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。

2.如何保障系统的高可用

* 单点是系统高可用的大敌，单点往往是系统高可用最大的风险和敌人，应该尽量在系统设计的过程中避免单点。方法论上，高可用保证的原则是“集群化”，或者叫“冗余”：只有一个单点，挂了服务会受影响；如果有冗余备份，挂了还有其他backup能够顶上。
* 保证系统高可用，架构设计的核心准则是：冗余。
有了冗余之后，还不够，每次出现故障需要人工介入恢复势必会增加系统的不可服务实践。所以，又往往是通过“自动故障转移”来实现系统的高可用。
* 接下来我们看下典型互联网架构中，如何通过冗余+自动故障转移来保证系统的高可用特性

3.总结

* 高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。

* 方法论上，高可用是通过冗余+自动故障转移来实现的。

* 整个互联网分层系统架构的高可用，又是通过每一层的冗余+自动故障转移来综合实现的，具体的：

* （1）【客户端层】到【反向代理层】的高可用，是通过反向代理层的冗余实现的，常见实践是keepalived + virtual IP自动故障转移

* （2）【反向代理层】到【站点层】的高可用，是通过站点层的冗余实现的，常见实践是nginx与web-server之间的存活性探测与自动故障转移

* （3）【站点层】到【服务层】的高可用，是通过服务层的冗余实现的，常见实践是通过service-connection-pool来保证自动故障转移

* （4）【服务层】到【缓存层】的高可用，是通过缓存数据的冗余实现的，常见实践是缓存客户端双读双写，或者利用缓存集群的主从数据同步与sentinel保活与自动故障转移；更多的业务场景，对缓存没有高可用要求，可以使用缓存服务化来对调用方屏蔽底层复杂性

* （5）【服务层】到【数据库“读”】的高可用，是通过读库的冗余实现的，常见实践是通过db-connection-pool来保证自动故障转移

* （6）【服务层】到【数据库“写”】的高可用，是通过写库的冗余实现的，常见实践是keepalived + virtual IP自动故障转移


## 二、高并发
[https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959830&idx=1&sn=ce1c5a58caed227d7dfdbc16d6e1cea4&chksm=bd2d07ca8a5a8edc45cc45c4787cc72cf4c8b96fb43d2840c7ccd44978036a7d39a03dd578b5&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959830&idx=1&sn=ce1c5a58caed227d7dfdbc16d6e1cea4&chksm=bd2d07ca8a5a8edc45cc45c4787cc72cf4c8b96fb43d2840c7ccd44978036a7d39a03dd578b5&scene=21#wechat_redirect)
* 什么是高并发
* 高并发架构准则：垂直扩展，水平扩展
* 互联网分层架构，各层保证水平扩展的架构实践

1.什么是高并发

* 高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
* 高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。
* 响应时间：系统对请求做出响应的时间。例如系统处理一个HTTP请求需要200ms，这个200ms就是系统的响应时间。
* 吞吐量：单位时间内处理的请求数量。
* QPS：每秒响应请求数。在互联网领域，这个指标和吞吐量区分的没有这么明显。
* 并发用户数：同时承载正常使用系统功能的用户数量。例如一个即时通讯系统，同时在线量一定程度上代表了系统的并发用户数。

2.如何提升系统的并发能力

* 互联网分布式架构设计，提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。
* 垂直扩展：提升单机处理能力。垂直扩展的方式又有两种：
* （1）增强单机硬件性能，例如：增加CPU核数如32核，升级更好的网卡如万兆，升级更好的硬盘如SSD，扩充硬盘容量如2T，扩充系统内存如128G；
* （2）提升单机架构性能，例如：使用Cache来减少IO次数，使用异步来增加单服务吞吐量，使用无锁数据结构来减少响应时间；
* 在互联网业务发展非常迅猛的早期，如果预算不是问题，强烈建议使用“增强单机硬件性能”的方式提升系统并发能力，因为这个阶段，公司的战略往往是发展业务抢时间，而“增强单机硬件性能”往往是最快的方法。
* 不管是提升单机硬件性能，还是提升单机架构性能，都有一个致命的不足：单机性能总是有极限的。所以互联网分布式架构设计高并发终极解决方案还是水平扩展。
* 水平扩展：只要增加服务器数量，就能线性扩充系统性能。水平扩展对系统架构设计是有要求的，如何在架构各层进行可水平扩展的设计，以及互联网公司架构各层常见的水平扩展实践，是本文重点讨论的内容。

4.分层水平扩展架构实践

* 反向代理层的水平扩展
	* 反向代理层的水平扩展，是通过“DNS轮询”实现的：dns-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问dns-server，会轮询返回这些ip。

	* 当nginx成为瓶颈的时候，只要增加服务器数量，新增nginx服务的部署，增加一个外网ip，就能扩展反向代理层的性能，做到理论上的无限高并发。
* 点层的水平扩展
	* 站点层的水平扩展，是通过“nginx”实现的。通过修改nginx.conf，可以设置多个web后端。

	* 当web后端成为瓶颈的时候，只要增加服务器数量，新增web服务的部署，在nginx配置中配置上新的web后端，就能扩展站点层的性能，做到理论上的无限高并发。
* 服务层的水平扩展
	* 服务层的水平扩展，是通过“服务连接池”实现的。
	* 站点层通过RPC-client调用下游的服务层RPC-server时，RPC-client中的连接池会建立与下游服务多个连接，当服务成为瓶颈的时候，只要增加服务器数量，新增服务部署，在RPC-client处建立新的下游服务连接，就能扩展服务层性能，做到理论上的无限高并发。如果需要优雅的进行服务层自动扩容，这里可能需要配置中心里服务自动发现功能的支持。
* 数据层的水平扩展
	* 在数据量很大的情况下，数据层（缓存，数据库）涉及数据的水平扩展，将原本存储在一台服务器上的数据（缓存，数据库）水平拆分到不同服务器上去，以达到扩充系统性能的目的。
	* 互联网数据层常见的水平拆分方式有这么几种，以数据库为例：
	* 按照范围水平拆分
		* 每一个数据服务，存储一定范围的数据，上图为例：
			* user0库，存储uid范围1-1kw
			* user1库，存储uid范围1kw-2kw
			* 这个方案的好处是：
				* （1）规则简单，service只需判断一下uid范围就能路由到对应的存储服务；
				* （2）数据均衡性较好；
				* （3）比较容易扩展，可以随时加一个uid[2kw,3kw]的数据服务；
			* 不足是：
				* （1）请求的负载不一定均衡，一般来说，新注册的用户会比老用户更活跃，大range的服务请求压力会更大；
		* 按照哈希水平拆分
		* 每一个数据库，存储某个key值hash后的部分数据，上图为例：
		* user0库，存储偶数uid数据
		* user1库，存储奇数uid数据
		* 这个方案的好处是：
			* （1）规则简单，service只需对uid进行hash能路由到对应的存储服务；
			* （2）数据均衡性较好；
			* （3）请求均匀性较好；

		* 不足是：
		* （1）不容易扩展，扩展一个数据服务，hash方法改变时候，可能需要进行数据迁移；
	* 这里需要注意的是，通过水平拆分来扩充系统性能，与主从同步读写分离来扩充数据库性能的方式有本质的不同。
	* 通过水平拆分扩展数据库性能：
		* （1）每个服务器上存储的数据量是总量的1/n，所以单机的性能也会有提升；
		* （2）n个服务器上的数据没有交集，那个服务器上数据的并集是数据的全集；
		* （3）数据水平拆分到了n个服务器上，理论上读性能扩充了n倍，写性能也扩充了n倍（其实远不止n倍，因为单机的数据量变为了原来的1/n）；
	* 通过主从同步读写分离扩展数据库性能：
		* （1）每个服务器上存储的数据量是和总量相同；
		* （2）n个服务器上的数据都一样，都是全集；
		* （3）理论上读性能扩充了n倍，写仍然是单点，写性能不变；
	* 缓存层的水平拆分和数据库层的水平拆分类似，也是以范围拆分和哈希拆分的方式居多，就不再展开。

4.总结

* 高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
* 提高系统并发能力的方式，方法论上主要有两种：垂直扩展（Scale Up）与水平扩展（Scale Out）。前者垂直扩展可以通过提升单机硬件性能，或者提升单机架构性能，来提高并发性，但单机性能总是有极限的，互联网分布式架构设计高并发终极解决方案还是后者：水平扩展。
* 互联网分层架构中，各层次水平扩展的实践又有所不同：
	* （1）反向代理层可以通过“DNS轮询”的方式来进行水平扩展；
	* （2）站点层可以通过nginx来进行水平扩展；
	* （3）服务层可以通过服务连接池来进行水平扩展；
	* （4）数据库可以按照数据范围，或者数据哈希的方式来进行水平扩展；
* 各层实施水平扩展后，能够通过增加服务器数量的方式来提升系统的性能，做到理论上的性能无限。

	

## 三、反向代理
[https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651960131&idx=1&sn=a3bbcbe03f9e12d32ba751ce6ffae067&chksm=bd2d069f8a5a8f895fed39cad842f6f5a390bb18493f964b910270128f19f0b8af1d1f30b5c7&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651960131&idx=1&sn=a3bbcbe03f9e12d32ba751ce6ffae067&chksm=bd2d069f8a5a8f895fed39cad842f6f5a390bb18493f964b910270128f19f0b8af1d1f30b5c7&scene=21#wechat_redirect)
* 什么是代理与反向代理
* 如何实施反向代理
* 什么是四层/七层，有没有二层/三层呢？

1.场景：访问用户通过proxy请求被访问的真实服务器
> 路径：用户 -> proxy -> real-server

什么是代理？
> 回答：[proxy]代表[访问用户]，此时proxy是代理。

例如：
在家访问xxoo网站，不希望xxoo网站trace到我们的真实ip，于是就找一个proxy，通过proxy来访问，此时proxy代表用户，网站以为proxy的ip就是用户的ip。



什么是反向代理？
> 回答：[proxy]代表[被访问的服务器]，此时proxy是反向代理。
> 
> 例如： web-server希望对用户屏蔽高可用、屏蔽web-server扩展、web-server内网ip等细节，于是就找了一个proxy隔在中间，此时proxy代表web-server集群，用户以为proxy的ip就是被访问web-server的ip（web-server是集群，具体访问了哪个web-server，用户不知道），由于web-server集群有多台，此时反向代理服务器要具备负载均衡的功能。

一般怎么做反向代理，负载均衡？
> 回答：nginx/apache，lvs，F5

什么是四层（转发/交换），什么是七层（转发/交换）？
> 回答：这个是来源于OSI七层模型

```
层数	OSI参考模型		TCP/IP五层模型
1		应用层			应用层
2		表示层			应用层
3		会话层			应用层
4		传输层			传输层
5		网络层			网络层
6		数据链路层		数据链路层
7		物理层			物理层
```


> 大学“计算机网络”课程，之前都是用这个七层模型，新版教程用TCP/IP五层模型，这两个模型之间有一个对应关系如下：
> 
可以看到，四层是指传输层，七层是指应用层。

> 更具体的，对应到nginx反向代理hash：

> 四层：根据用户ip+port来做hash

> 七层：根据http协议中的某些属性来做hash

为什么中间少了几层？
> 回答：OSI应用层、表示层、会话层合并到TCP/IP的应用层啦。

上面有四层，七层，那有没有二层，三层呢？
> 回答：有

> 二层：根据数据链路层MAC地址完成数据交换

> 三层：根据网络层IP地址完成数据交换

## 四、负载均衡
[https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959585&idx=1&sn=0a9222cbfeb62a662edffafb7f0b43ae&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959585&idx=1&sn=0a9222cbfeb62a662edffafb7f0b43ae&scene=21#wechat_redirect)
* 什么是负载均衡
* 高并发架构准则：均匀
* 互联网分层架构，各层保证负载均衡的架构实践

1.什么是负载均衡

* 负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据【均匀】分摊到多个操作单元上执行，负载均衡的关键在于【均匀】。
* 常见互联网分布式架构如上，分为客户端层、反向代理nginx层、站点层、服务层、数据层。可以看到，每一个下游都有多个上游调用，只需要做到，每一个上游都均匀访问每一个下游，就能实现“将请求/数据【均匀】分摊到多个操作单元上执行”。
* 【客户端层】到【反向代理层】的负载均衡，是通过“DNS轮询”实现的：DNS-server对于一个域名配置了多个解析ip，每次DNS解析请求来访问DNS-server，会轮询返回这些ip，保证每个ip的解析概率是相同的。这些ip就是nginx的外网ip，以做到每台nginx的请求分配也是均衡的。
* 【反向代理层】到【站点层】的负载均衡，是通过“nginx”实现的。通过修改nginx.conf，可以实现多种负载均衡策略：
	* 1）请求轮询：和DNS轮询类似，请求依次路由到各个web-server
	* 2）最少连接路由：哪个web-server的连接少，路由到哪个web-server
	* 3）ip哈希：按照访问用户的ip哈希值来路由web-server，只要用户的ip分布是均匀的，请求理论上也是均匀的，ip哈希均衡方法可以做到，同一个用户的请求固定落到同一台web-server上，此策略适合有状态服务，例如session（58沈剑备注：可以这么做，但强烈不建议这么做，站点层无状态是分布式架构设计的基本原则之一，session最好放到数据层存储）
	* 4）…
* 【站点层】到【服务层】的负载均衡，是通过“服务连接池”实现的。
	* 上游连接池会建立与下游服务多个连接，每次请求会“随机”选取连接来访问下游服务。
* 【数据层】的负载均衡
	* 在数据量很大的情况下，由于数据层（db，cache）涉及数据的水平切分，所以数据层的负载均衡更为复杂一些，它分为“数据的均衡”，与“请求的均衡”。
		* 数据的均衡是指：水平切分后的每个服务（db，cache），数据量是差不多的。
		* 请求的均衡是指：水平切分后的每个服务（db，cache），请求量是差不多的。

业内常见的水平切分方式有这么几种：
.....

2.总结

* 负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一，它通常是指，将请求/数据【均匀】分摊到多个操作单元上执行，负载均衡的关键在于【均匀】。
* （1）【客户端层】到【反向代理层】的负载均衡，是通过“DNS轮询”实现的
* （2）【反向代理层】到【站点层】的负载均衡，是通过“nginx”实现的
* （3）【站点层】到【服务层】的负载均衡，是通过“服务连接池”实现的
* （4）【数据层】的负载均衡，要考虑“数据的均衡”与“请求的均衡”两个点，常见的方式有“按照范围水平切分”与“hash水平切分”


## 延伸阅读：《LVS为何不能取代DNS轮询》
[https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959595&idx=1&sn=5f0633afd24c547b895f29f6538baa99&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959595&idx=1&sn=5f0633afd24c547b895f29f6538baa99&scene=21#wechat_redirect)
* 什么是LVS，DNS轮询
* LVS解决什么问题
* DNS轮询解决什么问题
* LVS为何不能取代DNS轮询

1.问题域

* nginx、lvs、keepalived、f5、DNS轮询，每每提到这些技术，往往讨论的是接入层的这样几个问题：
	* 1）可用性：任何一台机器挂了，服务受不受影响
	* 2）扩展性：能否通过增加机器，扩充系统的性能
	* 3）反向代理+负载均衡：请求是否均匀分摊到后端的操作单元执行

2.上面那些名词都是干嘛的

* 由于每个技术人的背景和知识域不同，上面那些名词缩写（运维的同学再熟悉不过了），还是花1分钟简单说明一下（详细请自行“百度”）：
* 1）nginx：一个高性能的web-server和实施反向代理的软件
* 2）lvs：Linux Virtual Server，使用集群技术，实现在linux操作系统层面的一个高性能、高可用、负载均衡服务器
* 3）keepalived：一款用来检测服务状态存活性的软件，常用来做高可用
* 4）f5：一个高性能、高可用、负载均衡的硬件设备（听上去和lvs功能差不多？）
* 5）DNS轮询：通过在DNS-server上对一个域名设置多个ip解析，来扩充web-server性能及实施负载均衡的技术

3.架构演变进化过程

* 【裸奔时代（0）单机架构】
	* 1）浏览器通过DNS-server，域名解析到ip
	* 2）浏览器通过ip访问web-server
	* 缺点：
		* 1）非高可用，web-server挂了整个系统就挂了
		* 2）扩展性差，当吞吐量达到web-server上限时，无法扩容

	* 注：单机不涉及负载均衡的问题

* 【简易扩容方案（1）DNS轮询】
	* 假设tomcat的吞吐量是1000次每秒，当系统总吞吐量达到3000时，如何扩容是首先要解决的问题，DNS轮询是一个很容易想到的方案：
	* 1）多部署几份web-server，1个tomcat抗1000，部署3个tomcat就能抗3000
	* 2）在DNS-server层面，域名每次解析到不同的ip
	* 优点：
		* 1）零成本：在DNS-server上多配几个ip即可，功能也不收费
		* 2）部署简单：多部署几个web-server即可，原系统架构不需要做任何改造
		* 3）负载均衡：变成了多机，但负载基本是均衡
	* 缺点：
	* 1）非高可用：DNS-server只负责域名解析ip，这个ip对应的服务是否可用，DNS-server是不保证的，假设有一个web-server挂了，部分服务会受到影响
	* 2）扩容非实时：DNS解析有一个生效周期
	* 3）暴露了太多的外网ip

* 【简易扩容方案（2）nginx】
	* tomcat的性能较差，但nginx作为反向代理的性能就强多了，假设线上跑到1w，就比tomcat高了10倍，可以利用这个特性来做扩容：
	* 1）站点层与浏览器层之间加入了一个反向代理层，利用高性能的nginx来做反向代理
	* 2）nginx将http请求分发给后端多个web-server
	* 优点：
		* 1）DNS-server不需要动
		* 2）负载均衡：通过nginx来保证
		* 3）只暴露一个外网ip，nginx->tomcat之间使用内网访问
		* 4）扩容实时：nginx内部可控，随时增加web-server随时实时扩容
		* 5）能够保证站点层的可用性：任何一台tomcat挂了，nginx可以将流量迁移到其他tomcat
	* 缺点：
		* 1）时延增加+架构更复杂了：中间多加了一个反向代理层
		* 2）反向代理层成了单点，非高可用：tomcat挂了不影响服务，nginx挂了怎么办？

* 【高可用方案（3）keepalived】
	* 为了解决高可用的问题，keepalived出场了（之前的文章“使用shadow-master保证系统可用性”详细介绍过）：

	* 1）做两台nginx组成一个集群，分别部署上keepalived，设置成相同的虚IP，保证nginx的高可用
	* 2）当一台nginx挂了，keepalived能够探测到，并将流量自动迁移到另一台nginx上，整个过程对调用方透明
	* 优点：
		* 1）解决了高可用的问题
	* 缺点：
	* 1）资源利用率只有50%
	* 2）nginx仍然是接入单点，如果接入吞吐量超过的nginx的性能上限怎么办，例如qps达到了50000咧？

* 【scale up扩容方案（4）lvs/f5】
	* nginx毕竟是软件，性能比tomcat好，但总有个上限，超出了上限，还是扛不住。

	* lvs就不一样了，它实施在操作系统层面；f5的性能又更好了，它实施在硬件层面；它们性能比nginx好很多，例如每秒可以抗10w，这样可以利用他们来扩容，常见的架构图如下：
	* 1）如果通过nginx可以扩展多个tomcat一样，可以通过lvs来扩展多个nginx
	* 2）通过keepalived+VIP的方案可以保证可用性

* 【scale out扩容方案（5）DNS轮询】
	* 如之前文章所述，水平扩展，才是解决性能问题的根本方案，能够通过加机器扩充性能的方案才具备最好的扩展性。

	* facebook，google，baidu的PV是不是超过80亿呢，它们的域名只对应一个ip么，终点又是起点，还是得通过DNS轮询来进行扩容：
	* 1）通过DNS轮询来线性扩展入口lvs层的性能
	* 2）通过keepalived来保证高可用
	* 3）通过lvs来扩展多个nginx
	* 4）通过nginx来做负载均衡，业务七层路由

4.结论

* 1）接入层架构要考虑的问题域为：高可用、扩展性、反向代理+扩展均衡
* 2）nginx、keepalived、lvs、f5可以很好的解决高可用、扩展性、反向代理+扩展均衡的问题
* 3）水平扩展scale out是解决扩展性问题的根本方案，DNS轮询是不能完全被nginx/lvs/f5所替代的

## 延伸阅读：《异构服务器负载均衡及过载保护》
[https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959601&idx=1&sn=5684c39676b1f6d9366d9d15a2cdcec3&scene=21#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MjM5ODYxMDA5OQ==&mid=2651959601&idx=1&sn=5684c39676b1f6d9366d9d15a2cdcec3&scene=21#wechat_redirect)
* 如何动态标识服务的处理能力
* 如何实施异构服务器负载均衡
* 什么是过载保护
* 如何实施过载保护

1.通过“静态权重”标识service的处理能力

* 假设service-ip1的处理能力是service-ip2，service-ip3的处理能力的2倍，可以设置weight1=2，weight2=1，weight3=1，这样三个service连接被获取到的概率分别就是2/4，1/4，1/4，能够保证处理能力强的service分别到等比的流量，不至于资源浪费。
* 使用nginx做反向代理与负载均衡，就有类似的机制。
* 这个方案的优点是：简单，能够快速的实现异构服务器的负载均衡。
* 缺点也很明显：这个权重是固定的，无法自适应动态调整，而很多时候，服务器的处理能力是很难用一个固定的数值量化。

2.通过“动态权重”标识service的处理能力

* 动态权重设计
	* 1）用一个动态权重来标识每个service的处理能力，默认初始处理能力相同，即分配给每个service的概率相等；
	* 2）每当service成功处理一个请求，认为service处理能力足够，权重动态+1
	* 3）每当service超时处理一个请求，认为service处理能力可能要跟不上了，权重动态-10（权重下降会更快）
	* 4）为了方便权重的处理，可以把权重的范围限定为[0, 100]，把权重的初始值设为60分
	* 假设service-ip1，service-ip2，service-ip3的动态权重初始值weight1=weight2=weight3=60，刚开始时，请求分配给这3台service的概率分别是60/180，60/180，60/180，即负载是均衡的。

3.过载保护

* 互联网软件架构设计中所指的过载保护，是指当系统负载超过一个service的处理能力时，如果service不进行自我保护，可能导致对外呈现处理能力为0，且不能自动恢复的现象。而service的过载保护，是指即使系统负载超过一个service的处理能力，service让能保证对外提供有损的稳定服务。
* 最简易的方式，服务端设定一个负载阈值，超过这个阈值的请求压过来，全部抛弃。这个方式不是特别优雅。

4.如何借助“动态权重”来实施过载保护

* 1）如果某一个service的连接上，连续3个请求都超时，即连续-10分三次，客户端就可以认为，服务器慢慢的要处理不过来了，得给这个service缓一小口气，于是设定策略：接下来的若干时间内，例如1秒（或者接下来的若干个请求），请求不再分配给这个service；
* 2）如果某一个service的动态权重，降为了0（像连续10个请求超时，中间休息了3次还超时），客户端就可以认为，服务器完全处理不过来了，得给这个service喘一大口气，于是设定策略：接下来的若干时间内，例如1分钟（为什么是1分钟，根据经验，此时service一般在发生fullGC，差不多1分钟能回过神来），请求不再分配给这个service；
* 3）可以有更复杂的保护策略…

6.总结

* 1）service的负载均衡、故障转移、超时处理通常是RPC-client连接池层面来实施的
* 2）异构服务器负载均衡，最简单的方式是静态权重法，缺点是无法自适应动态调整
* 3）动态权重法，可以动态的根据service的处理能力来分配负载，需要有连接池层面的微小改动
* 4）过载保护，是在负载过高时，service为了保护自己，保证一定处理能力的一种自救方法
* 5）动态权重法，还可以用做service的过载保护



系统设计关于高可用系统的一些技术方案

* 技术	解决什么问题
* 扩展	通过冗余部署，避免单点故障
* 隔离	1.避免业务之间的相互影响 2. 机房隔离避免单点故障
* 解耦	减少依赖，减少相互间的影响
* 限流	遇到突发流量时，保证系统稳定
	* 漏桶算法
	* 令牌算法
	* 滑动窗口计数法
	* 动态限流 需要手动设定限流阈值
* 降级	牺牲非核心业务，保证核心业务的高可用
* 熔断	减少不稳定的外部依赖对核心服务的影响
* 自动化测试	通过完善的测试，减少发布引起的故障
* 灰度发布	灰度发布是速度与安全性作为妥协，能够有效减少发布故障

